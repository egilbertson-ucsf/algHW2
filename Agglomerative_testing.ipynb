{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw2skeleton import cluster as cl\n",
    "from hw2skeleton import io\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "aa3 = \"ALA CYS ASP GLU PHE GLY HIS ILE LYS LEU MET ASN PRO GLN ARG SER THR VAL TRP TYR\".split()\n",
    "aa_df = pd.DataFrame(0, index=list(aa3), columns=['Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_matrix(sites):\n",
    "    simMat = []\n",
    "    names = []\n",
    "    for i in range(len(sites)):\n",
    "        names.append(sites[i].name)\n",
    "        row = []\n",
    "        for j in range(len(sites)):\n",
    "            row.append(cl.compute_similarity(sites[i].counts,sites[j].counts))\n",
    "        simMat.append(row)\n",
    "    simMat = pd.DataFrame(simMat, columns = names, index = names)\n",
    "    \n",
    "    return simMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min(simMat):\n",
    "    min_value = simMat[simMat!=0].min()[0]\n",
    "    min_pair = [simMat[simMat!=0].idxmin()[0], simMat.index[0]]\n",
    "    for i in simMat:\n",
    "        if simMat[simMat!=0][i].min() < min_value:\n",
    "            min_pair = (simMat[simMat!=0][i].idxmin(), i)\n",
    "            min_value = simMat[simMat!=0][i].min()\n",
    "    return list(min_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_most_similar(df, pair):\n",
    "    return df.drop(pair, axis=0).drop(pair, axis =1)\n",
    "def name_cluster(num):\n",
    "    return str('c' + str(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cluster_center(cluster_list, sites_dict, aa_df):\n",
    "    sites = aa_df\n",
    "    for j in cluster_list:\n",
    "        sites += sites_dict[j].counts \n",
    "    return sites / len(sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in 136 active sites\n"
     ]
    }
   ],
   "source": [
    "sites = io.read_active_sites('data')\n",
    "sites_dict = {}\n",
    "for site in sites:\n",
    "    sites_dict[site.name] = site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simMat = compute_similarity_matrix(sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_new_cluster_sim(new_clust_avg, simMat_update, sites_dict, clusters):\n",
    "    newSim = []\n",
    "    for site in simMat_update.columns:\n",
    "        if site not in sites_dict:\n",
    "            s = compute_cluster_center(clusters[site], sites_dict, aa_df)\n",
    "        else:\n",
    "            s = sites_dict[site].counts\n",
    "        \n",
    "        newSim.append(cl.compute_similarity(new_clust_avg, s))\n",
    "    newSim.append(0.0)\n",
    "    return newSim\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_simMat(newSim, simMat_update, new_name):\n",
    "    simMat_update[new_name] = None\n",
    "    newRow = pd.DataFrame([newSim], columns = simMat_update.columns, index = [new_name])\n",
    "    simMat_update = simMat_update.append(newRow)\n",
    "    simMat_update[new_name] = newSim\n",
    "    \n",
    "    return simMat_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_cluster_dict(new_name, min_pair, clusters, sites_dict):\n",
    "    pair0 = []\n",
    "    pair1 = []\n",
    "    if min_pair[0] in clusters:\n",
    "        pair0 += unpack_cluster(clusters[min_pair[0]], sites_dict, clusters)\n",
    "        del clusters[min_pair[0]]\n",
    "    else:\n",
    "        pair0.append(sites_dict[min_pair[0]].name)\n",
    "    if min_pair[1] in clusters:\n",
    "        pair1 += unpack_cluster(clusters[min_pair[1]], sites_dict, clusters)\n",
    "        del clusters[min_pair[1]]\n",
    "    else:\n",
    "        pair1.append(sites_dict[min_pair[1]].name)\n",
    "    clusters[new_name] = pair0 + pair1\n",
    "    \n",
    "    return clusters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_loop(clusters, key, out_list):\n",
    "    for value in clusters[key]:\n",
    "        out_list.append(value)\n",
    "    return out_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_cluster(cluster_list, sites_dict, clusters):\n",
    "    out_list = []\n",
    "    for key in cluster_list:\n",
    "        if key not in sites_dict:\n",
    "            for value in clusters[key]:\n",
    "                out_list.append(value)\n",
    "        else:\n",
    "            out_list.append(key)\n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try to unpack combo clusters everytime they get inserted into a new cluster so that deep recursion isn't necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n"
     ]
    }
   ],
   "source": [
    "simMat_update = simMat.copy()\n",
    "c = 0\n",
    "clusters = {}\n",
    "while len(simMat_update) > 1:\n",
    "    print(c)\n",
    "    new_name = name_cluster(c)\n",
    "    c += 1\n",
    "    min_pair=find_min(simMat_update)\n",
    "    clust_sites = unpack_cluster(min_pair, sites_dict, clusters)\n",
    "    simMat_update = rm_most_similar(simMat_update, min_pair)\n",
    "    new_clust_avg = compute_cluster_center(clust_sites, sites_dict, aa_df)\n",
    "    newSim = compute_new_cluster_sim(new_clust_avg, simMat_update, sites_dict, clusters)\n",
    "    simMat_update = update_simMat(newSim, simMat_update, new_name)\n",
    "    clusters = update_cluster_dict(new_name, min_pair, clusters, sites_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
